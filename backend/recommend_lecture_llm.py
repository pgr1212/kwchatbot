# ============================================
# ğŸ“š SBERT ê¸°ë°˜ ê°•ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ + LLM ì„¤ëª… ìƒì„±
# ============================================

import os
import psycopg2
import numpy as np
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv

# ===== í™˜ê²½ë³€ìˆ˜ ë¡œë“œ =====
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ===== ê¸°ë³¸ ì„¤ì • =====
OPENAI_MODEL = "gpt-3.5-turbo"
PG_DSN = {
    "host": "localhost",
    "dbname": "kwchatbot_lec",
    "user": "postgres",
    "password": "kk003300kk*"
}
SIM_THRESHOLD = 0.25

# ===== SBERT ëª¨ë¸ =====
MODEL_PATH = "triplet_finetuned_model"
model = SentenceTransformer(MODEL_PATH)

# ===== OpenAI í´ë¼ì´ì–¸íŠ¸ =====
client = OpenAI(api_key=OPENAI_API_KEY)


# ============================================
# ğŸ”¹ 1ï¸âƒ£ ê°•ì˜ì •ë³´ ì¹´í…Œê³ ë¦¬ì—ì„œ ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
# ============================================
def _fetch_similar_chunks(query_embedding, top_k=1):
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    cur.execute(
        """
        SELECT 
            dc.doc_id,
            dc.chunk_id,
            dc.chunk_text,
            dc.category,
            1 - (e.embedding <#> %s::vector) AS similarity
        FROM embeddings e
        JOIN doc_chunks dc ON e.chunk_id = dc.chunk_id
        WHERE dc.category = 'ê°•ì˜ì •ë³´'
        ORDER BY e.embedding <#> %s::vector
        LIMIT %s;
        """,
        (query_embedding, query_embedding, top_k)
    )

    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows


# ============================================
# ğŸ”¹ 2ï¸âƒ£ ë™ì¼ ê³¼ëª©(doc_id)ì˜ ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸° (index=2 ì œì™¸)
# ============================================
def _fetch_all_chunks_by_doc(doc_id):
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    cur.execute(
        """
        SELECT chunk_index, chunk_text
        FROM doc_chunks
        WHERE doc_id = %s
          AND chunk_index != 2
        ORDER BY chunk_index ASC;
        """,
        (doc_id,)
    )

    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows


# ============================================
# ğŸ”¹ 3ï¸âƒ£ ì¶”ì²œ í•¨ìˆ˜ + LLM ì„¤ëª… ìƒì„±
# ============================================
def recommend_and_describe_course(user_query):
    # 1ï¸âƒ£ ì‚¬ìš©ì ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = model.encode(user_query).tolist()

    # 2ï¸âƒ£ ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
    rows = _fetch_similar_chunks(query_embedding, top_k=1)
    if not rows:
        return "â— ê´€ë ¨ ê°•ì˜ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 3ï¸âƒ£ ê°€ì¥ ìœ ì‚¬í•œ ê³¼ëª©(doc_id) ì„ íƒ
    best_doc_id = rows[0][0]
    best_sim = round(float(rows[0][4]), 4)

    # 4ï¸âƒ£ í•´ë‹¹ ê³¼ëª©ì˜ ëª¨ë“  ì²­í¬(ë‹¨, index=2 ì œì™¸) ê°€ì ¸ì˜¤ê¸°
    chunks = _fetch_all_chunks_by_doc(best_doc_id)
    if not chunks:
        return f"â— doc_id={best_doc_id} ì— ëŒ€í•œ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 5ï¸âƒ£ ê³¼ëª© í…ìŠ¤íŠ¸ í†µí•©
    full_text = "\n-----\n".join(
        [f"[{idx}] {txt}" for idx, txt in chunks]
    )

    # 6ï¸âƒ£ LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = """
    ë‹¹ì‹ ì€ ê´‘ìš´ëŒ€í•™êµ KW Chatbotì˜ ì§„ë¡œ ì¶”ì²œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
    ì•„ë˜ CONTEXTëŠ” íŠ¹ì • ê³¼ëª©ì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤.
    ê°•ì˜ì •ë³´ë¥¼ ìš”ì•½í•˜ê³ , ìœ„ ê°•ì˜ê°€ ì‚¬ìš©ìì˜ ëª©í‘œ ë‹¬ì„±(ì§„ë¡œ)ì— ì–´ë–»ê²Œ ë„ì›€ì´ ë ì§€
    í•™ìƒì—ê²Œ ì¹œì ˆí•˜ê²Œ ì¶”ê°€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

    """
    user_prompt = f"""
    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_query}

    [ê°•ì˜ ì •ë³´]
    {full_text}

    """

    # 7ï¸âƒ£ GPT í˜¸ì¶œ
    try:
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            temperature=0.5,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        description = resp.choices[0].message.content
    except Exception as e:
        description = f"â— GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    # 8ï¸âƒ£ ê²°ê³¼ ë°˜í™˜
    result = {
        "ì¶”ì²œ_ê°•ì˜_doc_id": best_doc_id,
        "ìœ ì‚¬ë„": best_sim,
        "ê°•ì˜_ë‚´ìš©": full_text,
        "LLM_ì„¤ëª…": description
    }

    return result


# ============================================
# ğŸ”¹ ì‹¤í–‰ ì˜ˆì‹œ
# ============================================
if __name__ == "__main__":
    query = "íšŒê³„ì‚¬ ë˜ê³  ì‹¶ì–´ìš”"
    print(f"\n[ì‚¬ìš©ì ì…ë ¥] {query}\n")

    rec = recommend_and_describe_course(query)

    if isinstance(rec, str):
        print(rec)
    else:
        print(f"ğŸ¯ ì¶”ì²œ ê°•ì˜ (doc_id={rec['ì¶”ì²œ_ê°•ì˜_doc_id']}, ìœ ì‚¬ë„={rec['ìœ ì‚¬ë„']})\n")
        print("ğŸ“˜ ê°•ì˜ ì •ë³´:\n", rec["ê°•ì˜_ë‚´ìš©"])
        print("\nğŸ’¬ LLM ì„¤ëª…:\n", rec["LLM_ì„¤ëª…"])
