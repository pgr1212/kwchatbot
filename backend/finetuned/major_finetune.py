import psycopg2
import json
import random

PG_DSN = {
    "host": "localhost",
    "dbname": "kwchatbot_lec",
    "user": "postgres",
    "password": "3864"
}

anchor_templates = [
    "{í•™ê³¼} ì „ê³µë¡œë“œë§µ ì•Œë ¤ì¤˜.",
    "{í•™ê³¼} ë¡œë“œë§µ ë³´ì—¬ì¤˜",
    "{í•™ê³¼}ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜."
    "{í•™ê³¼} ì „ê³µ ê´€ë ¨ ê°•ì˜ ì•Œë ¤ì¤˜",
    "{í•™ê³¼} ì „ê³µê³¼ëª©ì´ ë­ê°€ ìˆì–´?",
    "{í•™ê³¼} ì „ê³µë¡œë“œë§µ ì‚¬ì§„ ë³´ì—¬ì¤˜.",
    "{í•™ê³¼}ëŠ” ë¬´ìŠ¨ ê³µë¶€ë¥¼ í•´?",
    "ë‚˜ëŠ” {í•™ê³¼}ì¸ë° ì „ê³µë¡œë“œë§µì´ ë­ì•¼?"
]

# ì¶œë ¥ JSONL
out_path = "major_triplet_dataset.jsonl"
f = open(out_path, "w", encoding="utf-8")

# DB ì—°ê²°
conn = psycopg2.connect(**PG_DSN)
cur = conn.cursor()

# ğŸ”¥ 1) í•™ê³¼ì •ë³´ ì²­í¬ ê°€ì ¸ì˜¤ê¸°
cur.execute("""
    SELECT doc_id, chunk_text, chunk_index
    FROM doc_chunks
    WHERE category = 'í•™ê³¼ì •ë³´'
    ORDER BY doc_id, chunk_index
""")

rows = cur.fetchall()

# ğŸ”¥ 2) doc_id ê¸°ì¤€ìœ¼ë¡œ chunk ë³‘í•©
from collections import defaultdict
docs = defaultdict(list)

for doc_id, text, idx in rows:
    docs[doc_id].append(text)

# ğŸ”¥ 3) ì „ì²´ ë¬¸ì„œ í…ìŠ¤íŠ¸ ìƒì„±
full_docs = {}  # doc_id â†’ full_text
for doc_id, chunks in docs.items():
    full_text = " ".join(chunks)
    full_docs[doc_id] = full_text

# ğŸ”¥ 4) í•™ê³¼ëª…, ë‹¨ê³¼ëŒ€í•™ ë“±ì„ ì¶”ì¶œí•˜ëŠ” ê°„ë‹¨ íŒŒì„œ
def parse_major_info(text):
    # ì˜ˆ: "ë‹¨ê³¼ëŒ€í•™: ìì—°ê³¼í•™ëŒ€í•™\ní•™ê³¼: ìˆ˜í•™ê³¼\nì „ê³µë¡œë“œë§µ: URL"
    lines = text.split()
    college, major = None, None
    for i in range(len(lines)):
        if "ë‹¨ê³¼ëŒ€í•™:" in lines[i]:
            college = lines[i+1]
        if "í•™ê³¼:" in lines[i]:
            major = lines[i+1]
    return college, major


# ì „ì²´ doc ëª©ë¡
doc_list = list(full_docs.items())  # [(doc_id, full_text), ...]

for doc_id, full_text in doc_list:

    college, major = parse_major_info(full_text)

    if not major:
        continue

    positive = full_text

    # negative 5ê°œ (ìê¸° ìì‹  ì œì™¸)
    other_docs = [(d, t) for d, t in doc_list if d != doc_id]
    negative_samples = random.sample(other_docs, 8)

    for tmpl in anchor_templates:
        anchor = tmpl.format(í•™ê³¼=major)

        # 5ê°œì˜ negativeë¡œ 5ê°œì˜ Triplet ìƒì„±
        for neg_doc_id, neg_text in negative_samples:

            row = {
                "anchor": anchor,
                "positive": positive,
                "negative": neg_text
            }

            f.write(json.dumps(row, ensure_ascii=False) + "\n")

f.close()
cur.close()
conn.close()

print("ğŸ”¥ JSONL ìƒì„± ì™„ë£Œ!", out_path)
