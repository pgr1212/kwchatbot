import psycopg2
import json
import random
import re
from collections import defaultdict

# ================================================
# DB ì„¤ì •
# ================================================
PG_DSN = {
    "host": "localhost",
    "dbname": "kwchatbot_lec",
    "user": "postgres",
    "password": "3864"
}

OUTPUT_FILE = "lecture_triplet_dataset.jsonl"

# ================================================
# Anchor í…œí”Œë¦¿ (3ê°œ)
# ================================================
ANCHOR_NAME = "{êµê³¼ëª©ëª…} ê°•ì˜ ì •ë³´ ì•Œë ¤ì¤˜"
ANCHOR_KW1 = "{keyword} ê´€ë ¨ ê°•ì˜ ì•Œë ¤ì¤˜"
ANCHOR_KW2 = "{keyword} ë°°ìš°ëŠ” ìˆ˜ì—… ë­ ìˆì–´?"

# ================================================
# êµê³¼ëª©ëª… ê¸°ë°˜ keyword ì¶”ì¶œ
# ================================================
def extract_keywords_from_course_name(course_name):
    """
    - í•œê¸€ë§Œ ì¶”ì¶œ
    - ê³µë°± split
    - ê¸¸ì´ 1ì§œë¦¬ ì œì™¸
    - ìµœëŒ€ 2ê°œ keyword ì‚¬ìš©
    """
    # ì˜ˆ: "ìƒí™œì†ì˜ê¸€ë¡œë²Œê²½ì œ-GlobalEconomy" â†’ "ìƒí™œì†ì˜ê¸€ë¡œë²Œê²½ì œ"
    name = re.sub(r"[^ê°€-í£]", " ", course_name)

    # í•œê¸€ í† í° ë‚˜ëˆ„ê¸°
    tokens = re.findall(r"[ê°€-í£]+", name)

    # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œê±°
    clean = [t for t in tokens if len(t) > 1]

    # ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ keywordë¡œ ì‚¬ìš©
    return clean[:2] if clean else ["ê¸°ë³¸ì£¼ì œ"]

# ================================================
# JSONL íŒŒì¼ ì—´ê¸°
# ================================================
out = open(OUTPUT_FILE, "w", encoding="utf-8")

# ================================================
# DB ì—°ê²°
# ================================================
conn = psycopg2.connect(**PG_DSN)
cur = conn.cursor()

# ================================================
# ê°•ì˜ chunk ê°€ì ¸ì˜¤ê¸°
# ================================================
cur.execute("""
    SELECT doc_id, chunk_index, chunk_text
    FROM doc_chunks
    WHERE category = 'ê°•ì˜ì •ë³´'
    ORDER BY doc_id, chunk_index;
""")

rows = cur.fetchall()

lecture_docs = defaultdict(list)

for doc_id, idx, text in rows:
    lecture_docs[doc_id].append((idx, text))

# ================================================
# chunk ë³‘í•© + êµê³¼ëª©ëª… + keyword ì¶”ì¶œ
# ================================================
full_texts = {}
course_names = {}
keywords_map = {}

for doc_id, chunks in lecture_docs.items():

    # 1) chunk ë³‘í•©
    chunks_sorted = sorted(chunks, key=lambda x: x[0])
    full_text = " ".join(t for _, t in chunks_sorted)
    full_texts[doc_id] = full_text

    # 2) êµê³¼ëª©ëª… ì¶”ì¶œ
    course_name = None
    for _, t in chunks:
        if "êµê³¼ëª©ëª…:" in t:
            try:
                course_name = t.split("êµê³¼ëª©ëª…:")[1].split()[0]
            except:
                pass
            break

    if not course_name:
        course_name = f"ê°•ì˜{doc_id}"

    course_names[doc_id] = course_name

    # 3) keyword = **êµê³¼ëª©ëª… ê¸°ë°˜ only**
    kws = extract_keywords_from_course_name(course_name)
    keywords_map[doc_id] = kws

# ================================================
# Triplet ìƒì„±
# ================================================
doc_ids = list(full_texts.keys())

for doc_id in doc_ids:

    pos = full_texts[doc_id]
    cname = course_names[doc_id]
    kws = keywords_map[doc_id]

    # negative 3ê°œ ìƒ˜í”Œë§
    neg_ids = random.sample([d for d in doc_ids if d != doc_id], 3)

    # (1) êµê³¼ëª©ëª… anchor
    anchor_name = ANCHOR_NAME.format(êµê³¼ëª©ëª…=cname)
    for neg in neg_ids:
        out.write(json.dumps({
            "anchor": anchor_name,
            "positive": pos,
            "negative": full_texts[neg]
        }, ensure_ascii=False) + "\n")

    # (2) keyword anchor 2ê°œ (êµê³¼ëª©ëª… ê¸°ë°˜)
    for kw in kws[:2]:
        anchor_kw1 = ANCHOR_KW1.format(keyword=kw)
        anchor_kw2 = ANCHOR_KW2.format(keyword=kw)

        for neg in neg_ids:
            out.write(json.dumps({
                "anchor": anchor_kw1,
                "positive": pos,
                "negative": full_texts[neg]
            }, ensure_ascii=False) + "\n")

            out.write(json.dumps({
                "anchor": anchor_kw2,
                "positive": pos,
                "negative": full_texts[neg]
            }, ensure_ascii=False) + "\n")

# ì¢…ë£Œ
out.close()
conn.close()

print("ğŸ”¥ ê°•ì˜ Triplet JSONL ìƒì„± ì™„ë£Œ:", OUTPUT_FILE)
