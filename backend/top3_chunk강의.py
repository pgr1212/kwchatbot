import os
import json
import psycopg2
import numpy as np
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
from openai import OpenAI

# ===== .env ë¶ˆëŸ¬ì˜¤ê¸° =====
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# ===== DB ì„¤ì • =====
PG_DSN = {
    "host": "localhost",
    "dbname": "kwchatbot_lec",
    "user": "postgres",
    "password": "kk003300kk*"
}

# ===== SBERT ëª¨ë¸ =====

MODEL_PATH = "triplet_finetuned_model"
model = SentenceTransformer(MODEL_PATH)



# ============================================
# 1ï¸âƒ£ Weighted document scoring ê¸°ë°˜ ê²€ìƒ‰
# ============================================
def fetch_ranked_documents(query_embedding, db_categories):

    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    cur.execute(
        """
        SELECT 
            dc.chunk_id,
            dc.doc_id,
            dc.chunk_index,
            dc.chunk_text,
            dc.category,
            dc.chunk_metadata,
            1 - (e.embedding <#> %s::vector) AS similarity
        FROM embeddings e
        JOIN doc_chunks dc ON e.chunk_id = dc.chunk_id
        WHERE dc.category = ANY(%s)
        ORDER BY similarity DESC
        LIMIT 50;
        """,
        (query_embedding, db_categories)
    )

    rows = cur.fetchall()
    cur.close()
    conn.close()

    if not rows:
        return []

    doc_scores = {}
    doc_chunks = {}

    for row in rows:
        chunk_id, doc_id, idx, text, category, metadata, sim = row

        if doc_id not in doc_scores:
            doc_scores[doc_id] = 0
            doc_chunks[doc_id] = []

        weight = {0: 1.5, 1: 1.0, 2: 0.5}.get(idx, 1.0)

        doc_scores[doc_id] += float(sim) * weight

        doc_chunks[doc_id].append({
            "chunk_id": chunk_id,
            "chunk_index": idx,
            "text": text,
            "metadata": metadata,
            "similarity": float(sim),
            "weighted_sim": float(sim) * weight
        })

    ranked_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)
    top_docs = [doc_id for doc_id, _ in ranked_docs[:3]]

    return [(doc_id, doc_chunks[doc_id]) for doc_id in top_docs]


# ============================================
# 2ï¸âƒ£ ë¬¸ì„œ ì „ì²´ ì¡°ë¦½
# ============================================
def build_full_document(doc_id, chunk_list):

    chunk_list_sorted = sorted(chunk_list, key=lambda x: x["chunk_index"])
    full_text = "\n".join(c["text"] for c in chunk_list_sorted)
    metadata = chunk_list_sorted[0]["metadata"] if chunk_list_sorted else {}

    return full_text, metadata


# ============================================
# 3ï¸âƒ£ LLM RAG ìƒì„± (ì „ë‹¬ëœ context ì¶œë ¥)
# ============================================
def generate_llm_answer(user_query, docs):

    context_items = []

    for doc_id, chunk_list in docs:
        full_text, metadata = build_full_document(doc_id, chunk_list)
        meta_str = json.dumps(metadata, ensure_ascii=False, indent=2)

        context_items.append(
            f"[ ë¬¸ì„œ ID: {doc_id} ]\n"
            f"-----\në³¸ë¬¸:\n{full_text}\n\në©”íƒ€ë°ì´í„°:\n{meta_str}\n"
        )

    context = "\n".join(context_items)

    # ğŸ”¥ LLMì—ê²Œ ë³´ë‚¸ ë‚´ìš© ì§ì ‘ ì¶œë ¥
    print("\n========== ğŸ“¤ LLMì— ì „ë‹¬ëœ CONTEXT ==========\n")
    print(context)
    print("==============================================\n")

    system_msg = """
ë‹¹ì‹ ì€ ê´‘ìš´ëŒ€í•™êµ KW Chatbotì…ë‹ˆë‹¤.
ì•„ë˜ CONTEXTì— ê¸°ë°˜í•˜ì—¬ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
"""

    user_msg = f"{context}\n\nì§ˆë¬¸: {user_query}\n\nì •ë‹µ:"

    # ğŸ”¥ í”„ë¡¬í”„íŠ¸ ì „ì²´ ì¶œë ¥
    print("========== ğŸ“¤ LLM ìµœì¢… PROMPT ==========\n")
    print("SYSTEM:", system_msg)
    print("\nUSER:", user_msg)
    print("==========================================\n")

    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            temperature=0.0,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
        )
        return resp.choices[0].message.content

    except Exception as e:
        return f"[LLM ì˜¤ë¥˜] {str(e)}"


# ============================================
# 4ï¸âƒ£ ì‹¤í–‰ + ì¶œë ¥
# ============================================
def print_docs_and_llm(category_key, user_query):

    query_emb = model.encode(user_query).tolist()
    ranked_docs = fetch_ranked_documents(query_emb, [category_key])

    if not ranked_docs:
        print("â— ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ")
        return

    print("\n========== ğŸ” Top ë¬¸ì„œ (doc_id ê¸°ì¤€) ==========")
    for doc_id, chunks in ranked_docs:
        print(f"\nâ–¶ doc_id={doc_id} (ì´ {len(chunks)} ì²­í¬)")
        for c in chunks:
            print(f" - chunk_id: {c['chunk_id']}  sim={c['similarity']:.3f}  weighted={c['weighted_sim']:.3f}")

    print("\n========================================================\n")

    llm_ans = generate_llm_answer(user_query, ranked_docs)

    print("\n================ ğŸ’¬ LLM ìµœì¢… ë‹µë³€ ================\n")
    print(llm_ans)
    print("\n==================================================\n")


# ============================================
# ì‹¤í–‰ ì˜ˆì‹œ
# ============================================
if __name__ == "__main__":
    category = "ê°•ì˜ì •ë³´"
    query = "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ê°•ì˜ ì•Œë ¤ì¤˜"

    print_docs_and_llm(category, query)
